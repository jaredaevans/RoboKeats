{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TuE8IyHKgTaN",
    "outputId": "85f3fc82-1579-4c04-9114-5590d2191841"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "#if not tf.config.list_physical_devices('GPU'):\n",
    "#    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "#    if IS_COLAB:\n",
    "#        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from psutil import virtual_memory\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import re\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "#from gensim.models import Word2Vec\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "MK2Z2xwxgfzA",
    "outputId": "abc6f4d1-fb7e-4ffe-9ef8-24cbac31b99f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "Wed Jul 15 19:37:40 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   42C    P0    34W / 250W |    353MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Your runtime has 27.4 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n",
      "Number of accelerators:  1\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found')\n",
    "else:\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "    print('and then re-execute this cell.')\n",
    "else:\n",
    "    print(gpu_info)\n",
    "\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "    print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "    print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "    print('re-execute this cell.')\n",
    "else:\n",
    "    print('You are using a high-RAM runtime!')\n",
    "\n",
    "try: # detect TPUs\n",
    "    # detect and init the TPU\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "    # instantiate a distribution strategy\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except ValueError: # detect GPUs\n",
    "    #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
    "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
    "    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_HOvvSPYi2V4"
   },
   "outputs": [],
   "source": [
    "!tar -xzf RomanticsTexts.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Im2y3e3AgTbb"
   },
   "source": [
    "# Text preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69sUJI_zgTbg"
   },
   "outputs": [],
   "source": [
    "# Text cleaning functions:\n",
    "def deRomanNumeral(words): #note: doesn't remove roman numeral I, as that is used often...\n",
    "    pattern = '^(cm?|cd?|d?c?c?c?)(xc?|xl?|l?x?x?x?)(ix|iv|v?i?ii)$'\n",
    "    words = [ w for w in words if re.search(pattern,w) is not None ]\n",
    "    return words\n",
    "\n",
    "# Text cleaning functions:\n",
    "def checkRomanNumeral(word): #note: doesn't remove roman numeral I, as that is used often...\n",
    "    if word == 'i':\n",
    "        return None\n",
    "    pattern = '^(cm?|cd?|d?c?c?c?)(xc?|xl?|l?x?x?x?)(m|d|c|x|v|l|ix|iv|v?i?i?i)$'\n",
    "    return re.search(pattern,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ObP7aJhgTbj"
   },
   "outputs": [],
   "source": [
    "def newlinepartition(text):\n",
    "    # cut up a single entry\n",
    "    septext = text.split(\"\\n\\n\\n\")\n",
    "    if len(septext) == 2 and len(septext[0]) < 200:\n",
    "        return septext[1]\n",
    "    if len(septext) > 2:\n",
    "        newtext = []\n",
    "        for tt in septext:\n",
    "            if len(tt) < 100:\n",
    "                pass\n",
    "            elif tt[:9]=='FOOTNOTES':\n",
    "                print(\"removed footnotes\")\n",
    "                pass\n",
    "            elif tt[:9]=='LINENOTES':\n",
    "                print(\"removed linenotes\")\n",
    "                pass\n",
    "            elif tt[:9]=='NOTE':\n",
    "                print(\"removed note\")\n",
    "                pass\n",
    "            else:\n",
    "                newtext.append(tt)\n",
    "        if(len(newtext)>1):\n",
    "            print('check this text')\n",
    "        return \"\\n\\n\".join(newtext)\n",
    "    if len(septext) < 2:\n",
    "        print(\"assumed empty\")\n",
    "        return None\n",
    "    \n",
    "def cleanup_text_A(text): # Keats # Coleridge\n",
    "    words = text.replace(\"\\n\\n\",\"\\n\")\n",
    "    words = words.replace(\"\\n\",\" \\n \")\n",
    "    words = words.replace(\"-\",\" \")\n",
    "    words = words.replace(\".\",\" . \")\n",
    "    words = words.replace(\"!\",\" ! \")\n",
    "    words = words.replace(\"?\",\" ? \")\n",
    "    words = words.split(\" \")\n",
    "    table = str.maketrans('', '', '…”_-.,;!:?*/()[]{}0123456789\"')\n",
    "    stripped = [w.translate(table).lower() for w in words]\n",
    "    stripped = [w for w in stripped if not w=='' and not checkRomanNumeral(w)]\n",
    "    cleanedtext = \" \".join(stripped)\n",
    "    cleanedtext = cleanedtext.replace(\"\\n part \\n\",\"\\n\")\n",
    "    cleanedtext = cleanedtext.replace(\"part i \\n\",\"\")\n",
    "    cleanedtext = cleanedtext.replace(\"\\n book \\n\",\"\\n\")\n",
    "    cleanedtext = cleanedtext.replace(\"book i \\n\",\"\")\n",
    "    cleanedtext = cleanedtext.replace(\"\\n scene \\n\",\"\\n\")\n",
    "    cleanedtext = cleanedtext.replace(\"scene i \\n\",\"\")\n",
    "    cleanedtext = cleanedtext.replace(\"\\n \\n\",\"\\n\")\n",
    "    cleanedtext = cleanedtext.replace(\"\\n note \\n\", 'TERMINATE')\n",
    "    cleanedtext = cleanedtext.replace(\"\\n notes \\n\", 'TERMINATE')\n",
    "    cleanedtext = cleanedtext.replace(\"\\n footnote \\n\", 'TERMINATE')\n",
    "    cleanedtext = cleanedtext.replace(\"\\n footnotes \\n\", 'TERMINATE')\n",
    "    cleanedtext = cleanedtext.split('TERMINATE')[0]\n",
    "    cleanedtext = re.sub(\"(\\n |)verse (st|nd|rd|th) \\n\",\"\\n\", cleanedtext)\n",
    "    cleanedtext = cleanedtext.lstrip(\"i \")\n",
    "    cleanedtext = cleanedtext.split(\" ed \\n\")[-1] # remove editors notes in wordsworth (may be dangerous)\n",
    "    cleanedtext = cleanedtext.replace(\"composed published \",\"\")\n",
    "    cleanedtext = cleanedtext.lstrip(\"\\n\")\n",
    "    return cleanedtext\n",
    "\n",
    "def cleanup_text_B(text): \n",
    "    words = text.replace(\"\\n\\n\",\"\\n\")\n",
    "    words = words.replace(\"\\n\",\" \\n \")\n",
    "    words = words.replace(\"-\",\" \")\n",
    "    words = words.replace(\".\",\" . \")\n",
    "    words = words.replace(\"!\",\" ! \")\n",
    "    words = words.replace(\"?\",\" ? \")\n",
    "    words = words.split(\" \")\n",
    "    table = str.maketrans('', '', '…”_-.,;!:?*/()[]{}0123456789\"')\n",
    "    stripped = [w.translate(table).lower() for w in words]\n",
    "    stripped = [w for w in stripped if not w=='' and not checkRomanNumeral(w)]\n",
    "    cleanedtext = \" \".join(stripped)\n",
    "    cleanedtext = cleanedtext.replace(\"\\n part \\n\",\"\\n\")\n",
    "    cleanedtext = cleanedtext.replace(\"part i \\n\",\"\")\n",
    "    cleanedtext = cleanedtext.replace(\"\\n book \\n\",\"\\n\")\n",
    "    cleanedtext = cleanedtext.replace(\"book i \\n\",\"\")\n",
    "    cleanedtext = cleanedtext.replace(\"\\n scene \\n\",\"\\n\")\n",
    "    cleanedtext = cleanedtext.replace(\"scene i \\n\",\"\")\n",
    "    cleanedtext = cleanedtext.replace(\"\\n \\n\",\"\\n\")\n",
    "    cleanedtext = re.sub(\"(\\n |)verse (st|nd|rd|th) \\n\",\"\\n\", cleanedtext)\n",
    "    cleanedtext = cleanedtext.lstrip(\"i \")\n",
    "    cleanedtext = cleanedtext.lstrip(\"\\n\")\n",
    "    return cleanedtext\n",
    "    \n",
    "def split_into_works(maintext,iStart,iEnd, type='A'):\n",
    "    # first identify where legal / forewardend etc, set these to iStart and iEnd (with a +!)\n",
    "    textlist = []\n",
    "    for i in range(iStart,iEnd):\n",
    "        print(i)\n",
    "        text = newlinepartition(maintext[i])\n",
    "        if text is not None: \n",
    "            if type == 'A' or type == '-':\n",
    "                textlist.append(cleanup_text_A(text))\n",
    "            elif type == 'B':\n",
    "                textlist.append(cleanup_text_B(text))\n",
    "    return textlist\n",
    "\n",
    "def split_works_into_words(works):\n",
    "    return [l.split(\" \") for l in works ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZiF5q3ZgTbn"
   },
   "source": [
    "## Keats Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NML480M3gTbr"
   },
   "outputs": [],
   "source": [
    "filedictionary = {'Keats_1.txt': {'zones': 2, 'len': [8, 22], 'cleanup': 'A'},\n",
    "                  'Keats_2.txt':  {'zones': 2, 'len': [5, 37],'cleanup': 'A'},\n",
    "                  'Keats_3.txt': {'zones': 2, 'len': [6, 10], 'cleanup': 'A'},\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qKhhMeu_gTbx"
   },
   "outputs": [],
   "source": [
    "keatsfilelist = [ file for file in os.listdir() if file[-4:]=='.txt' if file[:5]=='Keats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3rhJnDtgTb0"
   },
   "outputs": [],
   "source": [
    "def read_and_process_file(idx,filelist=keatsfilelist):\n",
    "    filename = filelist[idx]\n",
    "    file = open(filename, 'rt')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    adict = filedictionary[filename]\n",
    "    # split into words by white space\n",
    "    Zones = text.split(\"***\")\n",
    "    lens = adict['len']\n",
    "    maintext = []\n",
    "    if adict['zones'] == 'asmain':\n",
    "        maintext = Zones\n",
    "    else:\n",
    "        maintext = Zones[adict['zones']].split(\"\\n\\n\\n\\n\\n\")\n",
    "    maintext = split_into_works(maintext,lens[0],lens[1],type=adict['cleanup'])\n",
    "    return maintext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iixDl6V5gTcb"
   },
   "outputs": [],
   "source": [
    "workslist = []\n",
    "for i in range(len(keatsfilelist)): \n",
    "    workslist+= read_and_process_file(i,keatsfilelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-l3HpwtqmI9A"
   },
   "outputs": [],
   "source": [
    "# set \\n to \"newln\" so that new lines are recorded\n",
    "def convert_newline(text, tagword = \"newln\"):\n",
    "    text = text.replace('\\n',tagword)\n",
    "    return text\n",
    "\n",
    "def convert_newlines(texts, tagword = \"newln\"):\n",
    "    newtexts = list()\n",
    "    for text in texts:\n",
    "        newtexts.append(convert_newline(text,tagword=tagword))\n",
    "    return newtexts\n",
    "\n",
    "tokenizer = Tokenizer(char_level = False)\n",
    "workslist_t = convert_newlines(workslist)\n",
    "tokenizer.fit_on_texts(workslist_t)\n",
    "total_words = len(tokenizer.word_index)+1 # +! for 0 offset\n",
    "token_texts = tokenizer.texts_to_sequences(workslist_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nxMKoX_pPZx"
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 30\n",
    "\n",
    "def gen_sequences_text(token_text,step=1,lseq=SEQ_LENGTH):\n",
    "    x, y = list(), list()\n",
    "    for i in range(0, len(token_text) - lseq,step):\n",
    "        x.append(token_text[i:i+lseq])\n",
    "        y.append(token_text[i+lseq])\n",
    "    return x, y\n",
    "\n",
    "def gen_sequences(token_texts, step = 1,lseq=SEQ_LENGTH):\n",
    "    x, y = list(), list()\n",
    "    for text in token_texts:\n",
    "        xt, yt = gen_sequences_text(text,step,lseq)\n",
    "        x += xt\n",
    "        y += yt\n",
    "    # use sparse representation\n",
    "    y = np.array(y)\n",
    "    return np.array(x), np.array(y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jc6rUcwqxc6n"
   },
   "outputs": [],
   "source": [
    "x, y = gen_sequences(token_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keatsEmbedded = load_model(\"keats_embedded_gen.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQqkKD1Uxx-c"
   },
   "outputs": [],
   "source": [
    "nLSTM = 256\n",
    "dEmbedding = 100\n",
    "\n",
    "keatsEmbedded = Sequential([Input(shape = (None,)),\n",
    "                            Embedding(total_words, dEmbedding),\n",
    "                            LSTM(nLSTM, return_sequences=True),\n",
    "                            Dropout(0.3),\n",
    "                            LSTM(nLSTM),\n",
    "                            Dropout(0.3),\n",
    "                            Dense(total_words,activation='softmax')\n",
    "                            ])\n",
    "keatsEmbedded.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4X9No5ZBmr4j",
    "outputId": "7bba4b7e-e1e7-4476-af1a-9d199c2593ae"
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 256\n",
    "\n",
    "history = keatsEmbedded.fit(x, y, epochs = epochs, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUwkXILngTcU"
   },
   "outputs": [],
   "source": [
    "# this allows to smooth out a distrubtion and equalize probabilities ()\n",
    "def reweight_distribution(orig, temp=1.,eps=1e-8):\n",
    "    new = np.exp(np.log(np.abs(orig)+eps) / temp)\n",
    "    return new / np.sum(new)\n",
    "\n",
    "def sample(preds, temp = 1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = reweight_distribution(preds, temp)\n",
    "    probs = np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probs)\n",
    "\n",
    "# start poem at least SEQ_LENGTH out from seed, which seems to minimize the connection to the seed\n",
    "# even with a fairly low temp, the results are pretty random\n",
    "def generate_poem(seed, model, temp=0.5, stoplen=100, trainlen = SEQ_LENGTH, tagword = \"newln\",printseed = False):\n",
    "    #print('begin poem')\n",
    "    outputtext = ' '\n",
    "    if type(seed[0])==str:\n",
    "        token_list_total = tokenizer.texts_to_sequences([seed])[0]\n",
    "    else:\n",
    "        token_list_total = seed\n",
    "    if printseed:\n",
    "        print('begin poem from seed: ' + \" \".join([tokenizer.index_word[i] for i in token_list_total] ))\n",
    "\n",
    "    startrecord = False\n",
    "    running = True\n",
    "    i, k = 0, 0 \n",
    "    while running:\n",
    "        token_list = token_list_total[-trainlen:]\n",
    "        token_list = np.reshape(token_list, (1,trainlen))\n",
    "\n",
    "        probs = model.predict(token_list,verbose=0)[0]\n",
    "        yind = sample(probs,temp = temp)\n",
    "        #print(str(yind)+\": \"+str(probs))\n",
    "        nextword = tokenizer.index_word[yind] if yind>0 else ''\n",
    "\n",
    "        k+=1\n",
    "        if nextword == tagword:\n",
    "            nextword = \"\\n\"\n",
    "        #sys.stdout.write( nextword + \" \")\n",
    "\n",
    "        if startrecord:\n",
    "            outputtext += nextword + ' '\n",
    "            i+=1\n",
    "\n",
    "        if nextword == '\\n' and k > trainlen:\n",
    "            if not startrecord:\n",
    "                #print('begin poem')\n",
    "                startrecord = True\n",
    "            if i > stoplen:\n",
    "                running = False  \n",
    "\n",
    "        token_list_total = np.concatenate((token_list_total,[yind]))\n",
    "\n",
    "    return outputtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "MQ5JC2jpEFQv",
    "outputId": "5e520802-16f5-48d9-d256-c415e9eb370f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " there stood a dote from an hollow noise \n",
      " about the gentle air she seem'd in ease \n",
      " sweet days and horrid on born moment stood \n",
      " o think all that a sudden fear \n",
      " its poor snake all high began and share \n",
      " the convuls'd began with rich same ease \n",
      " before by faint his little blue while far \n",
      " each incense coolness with all a trembling plains \n",
      " which every hast did out a pleasant tongue \n",
      " divine of summer tongue whose lucid snowy \n",
      " they gazed from each flowers for heaven again \n",
      " a same eyed splendour as the last green \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(generate_poem(x[np.random.randint(len(x))], keatsEmbedded, temp=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "t0OuYCgJbyts",
    "outputId": "22f969ae-f04a-4e25-e7c3-97f808ca4b26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking\n"
     ]
    }
   ],
   "source": [
    "# check passages of the poem that seem \"too good\" to make sure they aren't just quotes\n",
    "# (note: hasn;t come up yet)\n",
    "def come_original(phrase, workslist):\n",
    "    print(\"checking\")\n",
    "    notfound = True\n",
    "    for work in workslist:\n",
    "        k = work.find(phrase)\n",
    "        if k > 0: \n",
    "            notfound = False\n",
    "            print(work[k: k + 500]) \n",
    "    if notfound:\n",
    "        print(\"checking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQbm3H2zlrCl"
   },
   "outputs": [],
   "source": [
    "keatsEmbedded.save(\"keats_embedded_gen.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "_FAyqqaKgTbN"
   ],
   "machine_shape": "hm",
   "name": "KeatsEmbeddingGen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
